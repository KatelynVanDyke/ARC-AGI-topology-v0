{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37021ee3aa0c025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T22:24:56.327648Z",
     "start_time": "2025-12-06T22:24:56.273020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8f22c2ad7a1b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T22:24:56.340338Z",
     "start_time": "2025-12-06T22:24:56.334760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to parse ARC-AGI task\n",
    "def load_arc_agi_task(raw):\n",
    "\n",
    "    train_inputs  = [np.array(p[\"input\"])  for p in raw[\"train\"]]\n",
    "    train_outputs = [np.array(p[\"output\"]) for p in raw[\"train\"]]\n",
    "\n",
    "    test_inputs   = [np.array(p[\"input\"])  for p in raw[\"test\"]]\n",
    "    test_outputs  = [np.array(p[\"output\"]) for p in raw[\"test\"]]\n",
    "\n",
    "    return {\n",
    "        \"train_inputs\": train_inputs,\n",
    "        \"train_outputs\": train_outputs,\n",
    "        \"test_inputs\": test_inputs,\n",
    "        \"test_outputs\": test_outputs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2c842be50bec54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T22:24:56.347542Z",
     "start_time": "2025-12-06T22:24:56.344608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load all tasks from directory\n",
    "def load_directory(path: Path):\n",
    "\n",
    "    tasks = {}\n",
    "\n",
    "    for file in path.glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            raw_json = json.load(f)\n",
    "        tasks[file.stem] = load_arc_agi_task(raw_json)\n",
    "\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e6e0af29c4dc4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T22:25:02.393834Z",
     "start_time": "2025-12-06T22:24:56.353992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " - training tasks: 400\n",
      " - evaluation tasks: 400\n"
     ]
    }
   ],
   "source": [
    "# Load training and evaluation data\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "ARC_DIR = DATA_DIR / \"arc1\"\n",
    "\n",
    "TRAIN_DIR = ARC_DIR / \"training\"\n",
    "EVAL_DIR  = ARC_DIR / \"evaluation\"\n",
    "\n",
    "training = load_directory(TRAIN_DIR)\n",
    "evaluation = load_directory(EVAL_DIR)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\" - training tasks:\", len(training))\n",
    "print(\" - evaluation tasks:\", len(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a369f0b00e488572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T22:25:02.444001Z",
     "start_time": "2025-12-06T22:25:02.402845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed_training.pkl and parsed_evaluation.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save parsed data to pickle files\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "\n",
    "with open(\"outputs/parsed_training.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training, f)\n",
    "\n",
    "with open(\"outputs/parsed_evaluation.pkl\", \"wb\") as f:\n",
    "    pickle.dump(evaluation, f)\n",
    "\n",
    "print(\"Saved parsed_training.pkl and parsed_evaluation.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
